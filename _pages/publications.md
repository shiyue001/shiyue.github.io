---
layout: archive
title: "Publications"
permalink: /publications/
author_profile: true
redirect_from:
  - /resume
---
{% include base_path %}

<ul>
  <li>
    <p>Geometric granularity aware pixel-to-mesh<br /><strong>Yue Shi</strong>, Bingbing Ni, Jinxian Liu, Dingyi Rong, Ye Qian, Wenjun Zhang<br /> Proceedings of the IEEE/CVF International Conference on Computer Vision (<strong>ICCV</strong>)，2021.<br /> [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Shi_Geometric_Granularity_Aware_Pixel-To-Mesh_ICCV_2021_paper.pdf">Paper</a>]</p>
  </li>
  <li>
    <p>GARF: Geometry-aware generalized neural radiance field<br /><strong>Yue Shi</strong>, Dingyi Rong, Bingbing Ni, Chang Chen, Wenjun Zhang<br /> arXiv preprint, 2022.<br /> [<a href="https://arxiv.org/pdf/2212.02280.pdf">Paper</a>]</p>
  </li>
  <li>
    <p>Learning Geometry and Appearance for Improved Radiance Fields Editing<br /><strong>Yue Shi</strong>, Rui Shi, Yuxuan Xiong, Bingbing Ni, Wenjun Zhang.<br /> [<a href="https://drive.google.com/file/d/1hVSAEM82ibnsklURHG0SC8ZoE7RYStew/view?usp=drive_link">Demo Link.</a>]</p>
  </li>
  <li>
    <p>USR: Unsupervised separated 3d garment and human reconstruction via geometry and semantic consistency<br /><strong>Yue Shi</strong>, Yuxuan Xiong, Bingbing Ni, Wenjun Zhang<br /> arXiv preprint, 2023.<br /> [<a href="https://arxiv.org/pdf/2302.10518.pdf">Paper</a>][<a href="https://github.com/shiyue001/USR">Code</a>]</p>
  </li>
  <li>
    <p>FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly<br />Yuhan Li，Yishun Dou, <strong>Yue Shi</strong>, Yu Lei, Xuanhong Chen, Yi Zhang, Peng Zhou, Bingbing Ni<br /> arXiv preprint, 2023.<br /> [<a href="https://arxiv.org/pdf/2308.10608.pdf">Paper</a>]</p>
  </li>
</ul>

If you find my works or codes help, please consider citing me. (●°u°●) 」
